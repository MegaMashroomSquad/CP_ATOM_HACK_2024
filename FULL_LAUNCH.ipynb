{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "torch.set_default_device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in /home/nick/.local/lib/python3.10/site-packages (1.5.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/nick/.local/lib/python3.10/site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /home/nick/.local/lib/python3.10/site-packages (from scikit-learn) (2.1.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/nick/.local/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/nick/.local/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обрабатываем SSTS файлы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docx2python import docx2python\n",
    "import re\n",
    "\n",
    "def parse_docx_text_SSTS(file_path):\n",
    "    docx_content = docx2python(file_path)\n",
    "    text_content = docx_content.text\n",
    "\n",
    "    sections = {}\n",
    "    section_index = None\n",
    "    current_section = []\n",
    "    pre_section_content = []\n",
    "\n",
    "    for line in text_content.split('\\n'):\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "\n",
    "        pattern = r'\\((?:[^()]*[&|][^()]*)+\\)'\n",
    "        pattern2 = r'\\((?:[a-zA-Z](?:[|&][a-zA-Z])*)\\)'\n",
    "        match = re.search(pattern2, line)\n",
    "        if match:\n",
    "            if current_section and section_index is not None:\n",
    "                sections[section_index] = ' '.join(current_section)\n",
    "            elif not section_index:\n",
    "                # If no section has been started yet, store pre-section content\n",
    "                sections[\"pre_section\"] = ' '.join(pre_section_content)\n",
    "            section_index = line  # Use the entire line as the section index\n",
    "            current_section = [line]\n",
    "        else:\n",
    "            if section_index is None:\n",
    "                pre_section_content.append(line)\n",
    "            else:\n",
    "                current_section.append(line)\n",
    "\n",
    "    if current_section and section_index is not None:\n",
    "        sections[f\"{section_index}.\"] = ' '.join(current_section)\n",
    "\n",
    "    return sections\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заменяем алгебру логики: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81a5c96fdf8a469a9cc527d02174e356",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "device = \"cuda\" # the device to load the model onto\n",
    "\n",
    "model_name = \"Qwen/Qwen2.5-14B-Instruct\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"cuda\",\n",
    "    cache_dir=\"/home/dev/llm_weights\"\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(prompt, system_prompt=None, max_new_tokens=1):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\" if system_prompt is None else system_prompt},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "    text = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "    model_inputs = tokenizer([text], return_tensors=\"pt\").to(device)\n",
    "\n",
    "    generated_ids = model.generate(\n",
    "        model_inputs.input_ids,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        temperature=0.00000001,\n",
    "    )\n",
    "    generated_ids = [\n",
    "        output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "    ]\n",
    "\n",
    "    response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "\n",
    "    return response\n",
    "\n",
    "\n",
    "def translate_logical_expression(expression):\n",
    "    prompt = f\"\"\"EXAMPLES: \n",
    "         TASK: Convert (a|b) into natural english. RESPONSE: a or b should be true.\n",
    "         TASK: Convert (a&b) into natural english. RESPONSE: a and b both should be true.\n",
    "         TASK: Convert ((a&c)|(b&d)) into natural english. RESPONSE: both a and c should be true OR both b and d should be true.\n",
    "         \n",
    "         TASK: Convert the logical expression {expression} into natural English. Provide only the translation in a single clear sentence. RESPONSE:\"\"\"\n",
    "    return generate(prompt, max_new_tokens=64)\n",
    "\n",
    "\n",
    "import re\n",
    "\n",
    "def replace_boolean_algebra_with_translation(text):\n",
    "    # Regex pattern to match boolean algebra expressions\n",
    "    pattern = r'\\((?:[^()]*[&|][^()]*)+\\)' \n",
    "    pattern2 = r'\\((?:[a-zA-Z](?:[|&][a-zA-Z])*)\\)'\n",
    "\n",
    "    # Split the text into lines\n",
    "    lines = text.split('\\n')\n",
    "    \n",
    "    for i, line in enumerate(lines):\n",
    "        # Find all boolean algebra expressions in the line\n",
    "        matches = re.findall(pattern2, line)\n",
    "        for match in matches:\n",
    "            # Translate each expression and replace it in the line\n",
    "            translation = translate_logical_expression(match)\n",
    "            translation = \"(\" + translation + \")\"\n",
    "            line = line.replace(match, translation)\n",
    "        lines[i] = line\n",
    "    \n",
    "    # Join the lines back into a single string\n",
    "    return '\\n'.join(lines)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Раскидываем текст по разным заголовкам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def structure_text_hmi(text):\n",
    "    structured_text = {\n",
    "        \"preconditions\": [],\n",
    "        \"main_scenario\": [],\n",
    "        \"postconditions\": []\n",
    "    }\n",
    "\n",
    "    current_section = None\n",
    "\n",
    "    import string\n",
    "\n",
    "    scenario_counter = 0\n",
    "    for line in text.split(\"\\n\"):\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        from fuzzywuzzy import fuzz\n",
    "\n",
    "        if fuzz.partial_ratio(\"Preconditions\", line) > 95:\n",
    "            current_section = \"preconditions\"\n",
    "        elif fuzz.partial_ratio(\"Main Scenario\", line) > 95:\n",
    "            current_section = \"main_scenario\"\n",
    "        elif fuzz.partial_ratio(\"Postconditions\", line) > 95:\n",
    "            current_section = \"postconditions\"\n",
    "        elif fuzz.partial_ratio(\"Alternative Scenario\", line) > 95:\n",
    "            scenario_counter += 1\n",
    "            current_section = f\"alternative_scenario_{string.ascii_uppercase[scenario_counter - 1]}\"\n",
    "            structured_text[current_section] = []  # Start a new list for each alternative scenario\n",
    "        elif current_section:\n",
    "            structured_text[current_section].append(line.strip())\n",
    "\n",
    "    return structured_text\n",
    "\n",
    "def structure_text_to_dict_hmi(text_content):\n",
    "    structured_text = structure_text_hmi(text_content)\n",
    "    section_dict = {}\n",
    "\n",
    "    \n",
    "    for section, lines in structured_text.items():\n",
    "        if section == \"alternative_scenarios\":\n",
    "            section_text = []\n",
    "            for scenario in lines:\n",
    "                scenario_text = \"\\n\".join(scenario)\n",
    "                section_text.append(scenario_text)\n",
    "            section_dict[section] = section_text\n",
    "        else:\n",
    "            section_text = \"\\n\".join(lines)\n",
    "            section_dict[section] = section_text\n",
    "\n",
    "    return section_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример использования:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Fact:\n",
    "    def __init__(self, text, doc_name, section_name):\n",
    "        self.text = text  # текст утверждения\n",
    "        self.doc_name = doc_name  # название дока\n",
    "        self.section_name = section_name  # название секции внутри которой находится факт\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"Text: {self.text}, DocName: {self.doc_name}, SectionName: {self.section_name}\"\n",
    "\n",
    "\n",
    "def process_docx_file_SSTS(file_path):\n",
    "    docx_content = docx2python(file_path)\n",
    "    text_content = docx_content.text\n",
    "    first_line = text_content.split('\\n', 1)[0]\n",
    "\n",
    "    sections = parse_docx_text_SSTS(file_path)\n",
    "    facts = []\n",
    "    for section, content in sections.items():\n",
    "        translated_content = replace_boolean_algebra_with_translation(content)\n",
    "        fact = Fact(text=translated_content, doc_name=first_line, section_name=section)\n",
    "        facts.append(fact)\n",
    "    return facts\n",
    "\n",
    "\n",
    "def process_file_hmi(file_path):\n",
    "    docx_content = docx2python(file_path)\n",
    "    text_content = docx_content.text\n",
    "    first_line = text_content.split('\\n', 1)[0]\n",
    "\n",
    "    sections_dict = structure_text_to_dict_hmi(text_content)\n",
    "    facts = []\n",
    "    \n",
    "    for section, text in sections_dict.items():\n",
    "        translated_text = replace_boolean_algebra_with_translation(text)\n",
    "        fact = Fact(text=translated_text, doc_name=first_line, section_name=section)\n",
    "        facts.append(fact)\n",
    "    \n",
    "    return facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tell_about_fact(fact: Fact, is_rule=True):\n",
    "    l = \"A\" if is_rule else \"B\"\n",
    "    return f\"Statement {l} is taken from document with name {fact.doc_name}, section with name {fact.section_name}. Statement {l} text: {fact.text}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nick/.local/lib/python3.10/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    }
   ],
   "source": [
    "hmi_prefix = \"/home/dev/case_data/train Атом/train data/HMI/UC-\"\n",
    "ssts_prefix = \"/home/dev/case_data/train Атом/train data/SSTS/SSTS-\"\n",
    "\n",
    "doc_id = 28561\n",
    "\n",
    "hmi_file = f\"{hmi_prefix}{doc_id}.docx\"\n",
    "ssts_file = f\"{ssts_prefix}{doc_id}.docx\"\n",
    "\n",
    "rules_data = process_file_hmi(hmi_file)\n",
    "impl_data = process_docx_file_SSTS(ssts_file)\n",
    "\n",
    "fewshot_examples = []\n",
    "\n",
    "fewshot_examples.append([tell_about_fact(rules_data[0]), tell_about_fact(impl_data[0]), \"No\"])\n",
    "\n",
    "fewshot_examples.append([tell_about_fact(rules_data[0]), tell_about_fact(impl_data[2]), \"Yes\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(factA: Fact, factB: Fact):\n",
    "    system_prompt = \"You are a compliance analyst tasked with verifying whether an implementation complies with a given regulation.\"\n",
    "    user_prompt = f\"\"\"\n",
    "        Logical statement A about car component:\n",
    "        {factA}\n",
    "\n",
    "        Logical statement B about car component:\n",
    "        {factB}\n",
    "\n",
    "        If you think that dismatch between A and B can lead to some unpleasant accidents, for example car crash, print \"Yes\"\n",
    "        Otherwise print \"No\"\n",
    "\n",
    "        Write only one word \"Yes\" or \"No\"\n",
    "        Answer: \n",
    "    \"\"\"\n",
    "    return system_prompt, user_prompt\n",
    "\n",
    "\n",
    "def build_prompt_description(factA: Fact, factB: Fact):\n",
    "    system_prompt = \"You are a compliance analyst tasked with verifying whether an implementation complies with a given regulation.\"\n",
    "    user_prompt = f\"\"\"\n",
    "        You will be provided with two statements:\n",
    "\n",
    "        - Statement A (Regulation): Contains information from a regulation, policy, or specification outlining conditions and requirements.\n",
    "\n",
    "        - Statement B (Implementation): Contains a description of an implementation that may or may not comply with the regulation specified in Statement A.\n",
    "\n",
    "\n",
    "        Determine whether there are any discrepancies or inconsistencies between the regulation and the implementation.\n",
    "\n",
    "        Also try to make your answer concise, write only the main diff and do not any other information\n",
    "\n",
    "        Statement A text:\n",
    "        {factA.text}\n",
    "\n",
    "        Statement B text:\n",
    "        {factB.text}\n",
    "\n",
    "        Your concise discrepancy: \n",
    "    \"\"\"\n",
    "    return system_prompt, user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_facts(doc):\n",
    "        content = docx2python(doc).text\n",
    "        splitting_prompt = f\"\"\"You will see a document with list of rules and instructions. I need you to split into many little logical fragments. \n",
    "            Basically, I want you to give me a list of facts and list of keywords from a whole document. Output should be like:\n",
    "            1) <fact 1>\n",
    "            2) <fact 2>\n",
    "            3) <fact 3>\n",
    "            etc...\n",
    "            Write numbers and facts and only them\n",
    "            My document to split: {content}\n",
    "        \"\"\"\n",
    "        res = [x for x in generate(splitting_prompt, max_new_tokens=1000).split(\"\\n\")]\n",
    "        return res\n",
    "\n",
    "def find_disrepancies(rule_doc, impl_doc, calc_facts=False):\n",
    "\n",
    "    if calc_facts:\n",
    "        impl_data = get_facts(impl_doc)\n",
    "        rules_data = get_facts(rule_doc)\n",
    "        \n",
    "    else:\n",
    "        rules_data = process_file_hmi(rule_doc)\n",
    "        impl_data = process_docx_file_SSTS(impl_doc)\n",
    "\n",
    "    print(\"RULES LIST\")\n",
    "\n",
    "    for rule in rules_data:\n",
    "        print(rule)\n",
    "    \n",
    "    print(\"IMPL LIST\")\n",
    "\n",
    "    for impl in impl_data:\n",
    "        print(impl)\n",
    "    \n",
    "    res = []\n",
    "    for rule in rules_data:\n",
    "        for impl in impl_data:\n",
    "            system_prompt, user_prompt = build_prompt(rule, impl)\n",
    "            ans = generate(user_prompt, max_new_tokens=1)\n",
    "            print(ans.lower())\n",
    "            if ans.lower() == \"yes\":\n",
    "                system_prompt_descr, user_prompt_descr = build_prompt_description(rule, impl)\n",
    "                descr = generate(user_prompt_descr, system_prompt_descr, max_new_tokens=100).strip().strip(\"\\n\")\n",
    "                # system_prompt_severity, user_prompt_severity = build_prompt_severeness(descr)\n",
    "                # severe = generate(user_prompt_severity, system_prompt_severity, max_new_tokens=1)\n",
    "\n",
    "                res.append(\n",
    "                    \n",
    "                    impl\n",
    "                )\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RULES LIST\n",
      "1) Users can modify the name and password of the vehicle hotspot according to their needs.\n",
      "2) The use-case title is \"Setting Hotspot name & password\".\n",
      "3) The scope of the use-case is SWP.\n",
      "4) There is no trigger for this use-case.\n",
      "5) The actors involved are Driver and Owner.\n",
      "6) The precondition is that the IVI system must start up on SWP Android.\n",
      "7) In the main scenario, the user navigates to the hotspot page on SWP Android.\n",
      "8) The user clicks on the hotspot name or password to go to the modification page.\n",
      "9) The user modifies the name or password and clicks 'save'.\n",
      "10) The postcondition is that the hotspot name or password will be modified successfully.\n",
      "11) The requirements state that the hotspot name and password will be saved in the vehicle profile.\n",
      "12) After changing the password, previously connected devices need to enter the new password to reconnect.\n",
      "IMPL LIST\n",
      "1) Users can modify the name and password of the vehicle hotspot when the vehicle is in a stopped state.\n",
      "2) Enabling conditions include IVI system startup, user operation of SWP, and IVI hotspot being enabled.\n",
      "3) Trigger conditions involve users setting the hotspot name and password in SWP, prompting IVI_IFT to send commands to SGW.\n",
      "4) Execution output involves SGW changing the hotspot name and password and feeding back the values to IVI_IFT for display.\n",
      "5) IVI and SGW save the configured name and password after modification.\n",
      "6) After changing the password, previous devices cannot connect until the new password is entered.\n",
      "7) After the vehicle is powered off, IVI and SGW remember the hotspot name and password; SGW takes priority if there is inconsistency.\n",
      "8) Exit conditions include the vehicle system being powered off or IVI system shutdown.\n",
      "9) The hotspot name can be a combination of Russian, English, and numbers, supporting up to 32 bytes.\n",
      "10) The hotspot name does not support special characters or symbols except for \"_\".\n",
      "11) The minimum character limit for the hotspot name is one character.\n",
      "12) After exceeding the maximum input character limit, IVI_IFT sends a video stream to SWP to notify the user.\n",
      "13) SGW needs to feedback the setting results to IVI within 1 second after the user sets the hotspot name and password.\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n"
     ]
    }
   ],
   "source": [
    "res = find_disrepancies(hmi_file, ssts_file, calc_facts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impl_data = get_facts(hmi_file)\n",
    "# rules_data = get_facts(ssts_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Text: hotspot settings Functional Description Users can modify the name and password of the vehicle hotspot according to their needs. This function can only be used when the vehicle is in a stopped state., DocName: hotspot settings, SectionName: pre_section, Text: Enabling conditions (a, b, and c all should be true.): IVI system startup; User can operate SWP; IVI hotspot is enabled., DocName: hotspot settings, SectionName: Enabling conditions (a&b&c):, Text: Trigger conditions (a should be true.): Users set the hotspot name and password in SWP, and IVI_IFT sends vehicle/{VIN}/hardware/interfaces/hotspotNameCommand and vehicle/{VIN}/hardware/interfaces/hotspotPasswordCommand to SGW. Users set hotspot name and password on the SWP, IVI_IFT send vehicle/{VIN}/hardware/interfaces/hotspotNameCommand and vehicle/{VIN}/hardware/interfaces/hotspotPasswordCommand to SGW., DocName: hotspot settings, SectionName: Trigger conditions (a):, Text: Execution output (a, b, c, and d should all be true.): After SGW changes the hotspot name and password, it feeds back vehicle/{VIN}/hardware/interfaces/hotspotNameValue and vehicle/{VIN}/hardware/interfaces/hotspotPasswordValue to IVI_IFT, which then displays them. After SGW changes the hotspot name and password, it provides feedback on vehicle/{VIN}/hardware/interfaces/hotspotNameValue and vehicle/{VIN}/hardware/interfaces/hotspotPasswordValue to IVI_IFT for display. IVI and SGW save the configured name and password; After changing the password, the previous device cannot be connected. After entering the new password, the connection can be successful. After the vehicle is powered off, IVI and SGW remember the hot spot name and password. If IVI memory state is inconsistent with SGW, SGW shall take priority, DocName: hotspot settings, SectionName: Execution output (a&b&c&d):, Text: Exit conditions/Exit conditions (a should be true.): The vehicle system is powered off. IVI system shutdown. Notes: 1. The hotspot name can be a combination of Russian, English, and numbers. After entering, click Confirm to modify the personal name. IVI_IFT supports inputting up to cal.NameLength_Hotspot(Default,32byte,TBD) characters. When the maximum value is exceeded, IVI_IFT sends the video stream to SWP to remind the user that \"the maximum input characters have been exceeded\". The hotspot name does not support special characters and special symbols (except ordinary English and Russian characters, and \"_\"). Minimum character limit: at least one character. The hotspot name can be a combination of Russian, English, and numbers. After entering, click confirm to modify the personal name. IVI-IFT supports up to cal.NameLength_Hotspot(Default,32byte,TBD), when the maximum value is exceeded, IVI_IFT will send a video stream to SWP and prompt the user \"the maximum input character has been exceeded\". The hotspot name does not support special characters or symbols (except for regular English and characters Russian, as well as \"_\"). Minimum character limit: At least one character. 2. After the user sets the hotspot name and password, SGW needs to feed back the setting results to IVI within cal. HotspotSettingFeedbackTime (Default, 1s, TBD). After the user sets the hotspot name and password, SGW needs to feedback the setting results to IVI within cal. HotspotSettingFeedbackTime(Default,1s,TBD)., DocName: hotspot settings, SectionName: Exit conditions/Exit conditions (a):.]\n"
     ]
    }
   ],
   "source": [
    "print(impl_data[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Text: , DocName: [I-28561]  Setting Hotspot name & password, SectionName: preconditions, Text: 1)\t\tThe user guides to the hotspot page out_2. SWP Android.\n",
      "2)\t\tClick in_2. SWP Android the hotspot name or password to enter the modification page.\n",
      "3)\t\tThe user modifies the name or password and clicks 'save' in_2. SWP Android.\n",
      "Postcondition:\n",
      "1)\t\tThe hotspot name or password will be modified successfully.\n",
      "Requirements:\n",
      "1)\t\tThe hotspot name and password will be saved in the vehicle profile.\n",
      "2)\t\tAfter changing the password, the previous device needs to enter the new password to reconnect., DocName: [I-28561]  Setting Hotspot name & password, SectionName: main_scenario, Text: , DocName: [I-28561]  Setting Hotspot name & password, SectionName: postconditions]\n"
     ]
    }
   ],
   "source": [
    "print(rules_data[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode and print the response\n",
    "response = generate(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for doc_id 6583: 3.7890 seconds\n",
      "Time taken for doc_id 8692: 3.3809 seconds\n",
      "Time taken for doc_id 30371: 3.0284 seconds\n",
      "Average time taken per document: 3.3994 seconds\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "hmi_prefix = \"/home/dev/case_data/train Атом/train data/HMI/UC-\"\n",
    "ssts_prefix = \"/home/dev/case_data/train Атом/train data/SSTS/SSTS-\"\n",
    "\n",
    "doc_ids = [\n",
    "        6583,\n",
    "        # 8604,\n",
    "        8692,\n",
    "        # 8800,\n",
    "        # 11467,\n",
    "        # 25957,\n",
    "        # 26160,\n",
    "        # 26161,\n",
    "        # 26771,\n",
    "        # 28561,\n",
    "        30371,\n",
    "        # 31523\n",
    "    ]\n",
    "\n",
    "answer = []\n",
    "total_time = 0\n",
    "\n",
    "for doc_id in doc_ids:\n",
    "    \n",
    "    hmi_file = f\"{hmi_prefix}{doc_id}.docx\"\n",
    "    ssts_file = f\"{ssts_prefix}{doc_id}.docx\"\n",
    "    impl_data = get_facts(hmi_file)[:50]\n",
    "    rules_data = get_facts(ssts_file)[:50]\n",
    "    prompt = f\"\"\"\n",
    "Evaluate the compliance of the document with the requirements using the rating system below:\n",
    "\n",
    "**Compliance Categories:**\n",
    "- FC (Fully Compliant): Perfect! Nothing can be improved.\n",
    "- LC (Largely Compliant): Generally correct. Some improvements may be needed (described in comments). No need for review.\n",
    "- PC (Partially Compliant): Major deviations. Improvements needed (described in comments). After improvement, review is required.\n",
    "- NC (Non-Compliant): Not compliant. Needs to be re-done and re-reviewed. Directions for update shown in comments.\n",
    "- NA (Not Applicable): Not applicable. Reason for non-applicability is described in comments.\n",
    "\n",
    "### Instructions:\n",
    "1. Review the document content in \"File\" and compare it to the \"REQUIREMENTS\" provided.\n",
    "2. Based on this comparison, assign the appropriate two-letter compliance code (e.g., FC, LC, PC, NC, or NA).\n",
    "\n",
    "### Notice (few-shot):\n",
    "\n",
    "LC is returned if the notifications for battery status are slightly delayed, if the sound alerts for seatbelt reminders are missing, if the user interface occasionally lags for less than 1 second, if some minor glitches occur in the navigation system.\n",
    "\n",
    "PC is returned if the regenerative braking system fails to engage properly at lower speeds, affecting braking consistency, if the navigation system misinterprets an address occasionally,\n",
    "\n",
    "NC is returned if the emergency braking system fails to activate when necessary, posing a direct safety risk, if the battery management system reports inaccurate charge levels, function can only be used when the vehicle is in a stopped state.\n",
    "\n",
    "NA is returned if the test involves an audio system, if IVI_IFT sends a video stream to SWP to notify the user\n",
    "\n",
    "### Data:\n",
    "File: {impl_data}\n",
    "REQUIREMENTS: {rules_data}\n",
    "\n",
    "**Output Format**: Return ONLY ONE two-letter compliance code (e.g., FC, LC, PC, NC, or NA) as the final compliance rating. START YOUR ANSWER WITH THE CODE:\n",
    "\"\"\"\n",
    "\n",
    "    # Measure the time taken to generate the response\n",
    "    start_time = timeit.default_timer()\n",
    "    response = generate(prompt)\n",
    "    elapsed_time = timeit.default_timer() - start_time\n",
    "    total_time += elapsed_time\n",
    "    print(f\"Time taken for doc_id {doc_id}: {elapsed_time:.4f} seconds\")\n",
    "\n",
    "    answer.append(response)\n",
    "\n",
    "average_time = total_time / len(doc_ids)\n",
    "print(f\"Average time taken per document: {average_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PC', 'PC', 'LC']\n"
     ]
    }
   ],
   "source": [
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
