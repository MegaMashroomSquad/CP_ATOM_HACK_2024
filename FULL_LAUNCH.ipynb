{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "torch.set_default_device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in /home/nick/.local/lib/python3.10/site-packages (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/nick/.local/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/nick/.local/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/nick/.local/lib/python3.10/site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /home/nick/.local/lib/python3.10/site-packages (from scikit-learn) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обрабатываем SSTS файлы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docx2python import docx2python\n",
    "import re\n",
    "\n",
    "def parse_docx_text_SSTS(file_path):\n",
    "    docx_content = docx2python(file_path)\n",
    "    text_content = docx_content.text\n",
    "\n",
    "    sections = {}\n",
    "    section_index = None\n",
    "    current_section = []\n",
    "    pre_section_content = []\n",
    "\n",
    "    for line in text_content.split('\\n'):\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "\n",
    "        pattern = r'\\((?:[^()]*[&|][^()]*)+\\)'\n",
    "        pattern2 = r'\\((?:[a-zA-Z](?:[|&][a-zA-Z])*)\\)'\n",
    "        match = re.search(pattern2, line)\n",
    "        if match:\n",
    "            if current_section and section_index is not None:\n",
    "                sections[section_index] = ' '.join(current_section)\n",
    "            elif not section_index:\n",
    "                # If no section has been started yet, store pre-section content\n",
    "                sections[\"pre_section\"] = ' '.join(pre_section_content)\n",
    "            section_index = line  # Use the entire line as the section index\n",
    "            current_section = [line]\n",
    "        else:\n",
    "            if section_index is None:\n",
    "                pre_section_content.append(line)\n",
    "            else:\n",
    "                current_section.append(line)\n",
    "\n",
    "    if current_section and section_index is not None:\n",
    "        sections[f\"{section_index}.\"] = ' '.join(current_section)\n",
    "\n",
    "    return sections\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заменяем алгебру логики: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3afd9c2f071847d1986d50cdd87a9971",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "device = \"cuda\" # the device to load the model onto\n",
    "\n",
    "model_name = \"Qwen/Qwen2.5-14B-Instruct\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"cuda\",\n",
    "    cache_dir=\"/home/dev/llm_weights\"\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(prompt, system_prompt=None, max_new_tokens=1):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\" if system_prompt is None else system_prompt},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "    text = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "    model_inputs = tokenizer([text], return_tensors=\"pt\").to(device)\n",
    "\n",
    "    generated_ids = model.generate(\n",
    "        model_inputs.input_ids,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        temperature=0.00000001,\n",
    "    )\n",
    "    generated_ids = [\n",
    "        output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "    ]\n",
    "\n",
    "    response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "\n",
    "    return response\n",
    "\n",
    "\n",
    "def translate_logical_expression(expression):\n",
    "    prompt = f\"\"\"EXAMPLES: \n",
    "         TASK: Convert (a|b) into natural english. RESPONSE: a or b should be true.\n",
    "         TASK: Convert (a&b) into natural english. RESPONSE: a and b both should be true.\n",
    "         TASK: Convert ((a&c)|(b&d)) into natural english. RESPONSE: both a and c should be true OR both b and d should be true.\n",
    "         \n",
    "         TASK: Convert the logical expression {expression} into natural English. Provide only the translation in a single clear sentence. RESPONSE:\"\"\"\n",
    "    return generate(prompt, max_new_tokens=64)\n",
    "\n",
    "\n",
    "import re\n",
    "\n",
    "def replace_boolean_algebra_with_translation(text):\n",
    "    # Regex pattern to match boolean algebra expressions\n",
    "    pattern = r'\\((?:[^()]*[&|][^()]*)+\\)' \n",
    "    pattern2 = r'\\((?:[a-zA-Z](?:[|&][a-zA-Z])*)\\)'\n",
    "\n",
    "    # Split the text into lines\n",
    "    lines = text.split('\\n')\n",
    "    \n",
    "    for i, line in enumerate(lines):\n",
    "        # Find all boolean algebra expressions in the line\n",
    "        matches = re.findall(pattern2, line)\n",
    "        for match in matches:\n",
    "            # Translate each expression and replace it in the line\n",
    "            translation = translate_logical_expression(match)\n",
    "            translation = \"(\" + translation + \")\"\n",
    "            line = line.replace(match, translation)\n",
    "        lines[i] = line\n",
    "    \n",
    "    # Join the lines back into a single string\n",
    "    return '\\n'.join(lines)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Раскидываем текст по разным заголовкам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def structure_text_hmi(text):\n",
    "    structured_text = {\n",
    "        \"preconditions\": [],\n",
    "        \"main_scenario\": [],\n",
    "        \"postconditions\": []\n",
    "    }\n",
    "\n",
    "    current_section = None\n",
    "\n",
    "    import string\n",
    "\n",
    "    scenario_counter = 0\n",
    "    for line in text.split(\"\\n\"):\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        from fuzzywuzzy import fuzz\n",
    "\n",
    "        if fuzz.partial_ratio(\"Preconditions\", line) > 95:\n",
    "            current_section = \"preconditions\"\n",
    "        elif fuzz.partial_ratio(\"Main Scenario\", line) > 95:\n",
    "            current_section = \"main_scenario\"\n",
    "        elif fuzz.partial_ratio(\"Postconditions\", line) > 95:\n",
    "            current_section = \"postconditions\"\n",
    "        elif fuzz.partial_ratio(\"Alternative Scenario\", line) > 95:\n",
    "            scenario_counter += 1\n",
    "            current_section = f\"alternative_scenario_{string.ascii_uppercase[scenario_counter - 1]}\"\n",
    "            structured_text[current_section] = []  # Start a new list for each alternative scenario\n",
    "        elif current_section:\n",
    "            structured_text[current_section].append(line.strip())\n",
    "\n",
    "    return structured_text\n",
    "\n",
    "def structure_text_to_dict_hmi(text_content):\n",
    "    structured_text = structure_text_hmi(text_content)\n",
    "    section_dict = {}\n",
    "\n",
    "    \n",
    "    for section, lines in structured_text.items():\n",
    "        if section == \"alternative_scenarios\":\n",
    "            section_text = []\n",
    "            for scenario in lines:\n",
    "                scenario_text = \"\\n\".join(scenario)\n",
    "                section_text.append(scenario_text)\n",
    "            section_dict[section] = section_text\n",
    "        else:\n",
    "            section_text = \"\\n\".join(lines)\n",
    "            section_dict[section] = section_text\n",
    "\n",
    "    return section_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример использования:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Fact:\n",
    "    def __init__(self, text, doc_name, section_name):\n",
    "        self.text = text  # текст утверждения\n",
    "        self.doc_name = doc_name  # название дока\n",
    "        self.section_name = section_name  # название секции внутри которой находится факт\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"Text: {self.text}, DocName: {self.doc_name}, SectionName: {self.section_name}\"\n",
    "\n",
    "\n",
    "def process_docx_file_SSTS(file_path):\n",
    "    docx_content = docx2python(file_path)\n",
    "    text_content = docx_content.text\n",
    "    first_line = text_content.split('\\n', 1)[0]\n",
    "\n",
    "    sections = parse_docx_text_SSTS(file_path)\n",
    "    facts = []\n",
    "    for section, content in sections.items():\n",
    "        translated_content = content\n",
    "        fact = Fact(text=translated_content, doc_name=first_line, section_name=section)\n",
    "        facts.append(fact)\n",
    "    return facts\n",
    "\n",
    "\n",
    "def process_file_hmi(file_path):\n",
    "    docx_content = docx2python(file_path)\n",
    "    text_content = docx_content.text\n",
    "    first_line = text_content.split('\\n', 1)[0]\n",
    "\n",
    "    sections_dict = structure_text_to_dict_hmi(text_content)\n",
    "    facts = []\n",
    "    \n",
    "    for section, text in sections_dict.items():\n",
    "        translated_text = text\n",
    "        fact = Fact(text=translated_text, doc_name=first_line, section_name=section)\n",
    "        facts.append(fact)\n",
    "    \n",
    "    return facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tell_about_fact(fact: Fact, is_rule=True):\n",
    "    l = \"A\" if is_rule else \"B\"\n",
    "    return f\"Statement {l} is taken from document with name {fact.doc_name}, section with name {fact.section_name}. Statement {l} text: {fact.text}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmi_prefix = \"/home/dev/case_data/train Атом/train data/HMI/UC-\"\n",
    "ssts_prefix = \"/home/dev/case_data/train Атом/train data/SSTS/SSTS-\"\n",
    "\n",
    "doc_id = 28561\n",
    "\n",
    "hmi_file = f\"{hmi_prefix}{doc_id}.docx\"\n",
    "ssts_file = f\"{ssts_prefix}{doc_id}.docx\"\n",
    "\n",
    "rules_data = process_file_hmi(hmi_file)\n",
    "impl_data = process_docx_file_SSTS(ssts_file)\n",
    "\n",
    "fewshot_examples = []\n",
    "\n",
    "fewshot_examples.append([tell_about_fact(rules_data[0]), tell_about_fact(impl_data[0]), \"No\"])\n",
    "\n",
    "fewshot_examples.append([tell_about_fact(rules_data[0]), tell_about_fact(impl_data[2]), \"Yes\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(factA: Fact, factB: Fact):\n",
    "    system_prompt = \"You are a compliance analyst tasked with verifying whether an implementation complies with a given regulation.\"\n",
    "    user_prompt = f\"\"\"\n",
    "        Logical statement A about car component:\n",
    "        {factA}\n",
    "\n",
    "        Logical statement B about car component:\n",
    "        {factB}\n",
    "\n",
    "        If you think that dismatch between A and B can lead to some unpleasant accidents, for example car crash, print \"Yes\"\n",
    "        Otherwise print \"No\"\n",
    "\n",
    "        Write only one word \"Yes\" or \"No\"\n",
    "        Answer: \n",
    "    \"\"\"\n",
    "    return system_prompt, user_prompt\n",
    "\n",
    "\n",
    "def build_prompt_description(factA: Fact, factB: Fact):\n",
    "    system_prompt = \"You are a compliance analyst tasked with verifying whether an implementation complies with a given regulation.\"\n",
    "    user_prompt = f\"\"\"\n",
    "        You will be provided with two statements:\n",
    "\n",
    "        - Statement A (Regulation): Contains information from a regulation, policy, or specification outlining conditions and requirements.\n",
    "\n",
    "        - Statement B (Implementation): Contains a description of an implementation that may or may not comply with the regulation specified in Statement A.\n",
    "\n",
    "\n",
    "        Determine whether there are any discrepancies or inconsistencies between the regulation and the implementation.\n",
    "\n",
    "        Also try to make your answer concise, write only the main diff and do not any other information\n",
    "\n",
    "        Statement A text:\n",
    "        {factA.text}\n",
    "\n",
    "        Statement B text:\n",
    "        {factB.text}\n",
    "\n",
    "        Your concise discrepancy: \n",
    "    \"\"\"\n",
    "    return system_prompt, user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_facts(doc):\n",
    "        content = docx2python(doc).text\n",
    "        splitting_prompt = f\"\"\"You will see a document with list of rules and instructions. I need you to split into many little logical fragments. \n",
    "            Basically, I want you to give me a list of facts and list of keywords from a whole document. Output should be like:\n",
    "            1) <fact 1>\n",
    "            2) <fact 2>\n",
    "            3) <fact 3>\n",
    "            etc...\n",
    "            Write numbers and facts and only them\n",
    "            My document to split: {content}\n",
    "        \"\"\"\n",
    "        res = [x for x in generate(splitting_prompt, max_new_tokens=1000).split(\"\\n\")]\n",
    "        return res\n",
    "\n",
    "def find_disrepancies(rule_doc, impl_doc, calc_facts=False):\n",
    "\n",
    "    if calc_facts:\n",
    "        impl_data = get_facts(impl_doc)\n",
    "        rules_data = get_facts(rule_doc)\n",
    "        \n",
    "    else:\n",
    "        rules_data = process_file_hmi(rule_doc)\n",
    "        impl_data = process_docx_file_SSTS(impl_doc)\n",
    "\n",
    "    print(\"RULES LIST\")\n",
    "\n",
    "    for rule in rules_data:\n",
    "        print(rule)\n",
    "    \n",
    "    print(\"IMPL LIST\")\n",
    "\n",
    "    for impl in impl_data:\n",
    "        print(impl)\n",
    "    \n",
    "    res = []\n",
    "    for rule in rules_data:\n",
    "        for impl in impl_data:\n",
    "            system_prompt, user_prompt = build_prompt(rule, impl)\n",
    "            ans = generate(user_prompt, max_new_tokens=1)\n",
    "            print(ans.lower())\n",
    "            if ans.lower() == \"yes\":\n",
    "                system_prompt_descr, user_prompt_descr = build_prompt_description(rule, impl)\n",
    "                descr = generate(user_prompt_descr, system_prompt_descr, max_new_tokens=100).strip().strip(\"\\n\")\n",
    "                # system_prompt_severity, user_prompt_severity = build_prompt_severeness(descr)\n",
    "                # severe = generate(user_prompt_severity, system_prompt_severity, max_new_tokens=1)\n",
    "\n",
    "                res.append(\n",
    "                    \n",
    "                    impl\n",
    "                )\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfind_disrepancies\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhmi_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mssts_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcalc_facts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[39], line 18\u001b[0m, in \u001b[0;36mfind_disrepancies\u001b[0;34m(rule_doc, impl_doc, calc_facts)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind_disrepancies\u001b[39m(rule_doc, impl_doc, calc_facts\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m calc_facts:\n\u001b[0;32m---> 18\u001b[0m         impl_data \u001b[38;5;241m=\u001b[39m \u001b[43mget_facts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimpl_doc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m         rules_data \u001b[38;5;241m=\u001b[39m get_facts(rule_doc)\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[39], line 12\u001b[0m, in \u001b[0;36mget_facts\u001b[0;34m(doc)\u001b[0m\n\u001b[1;32m      2\u001b[0m content \u001b[38;5;241m=\u001b[39m docx2python(doc)\u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m      3\u001b[0m splitting_prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mYou will see a document with list of rules and instructions. I need you to split into many little logical fragments. \u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124m    Basically, I want you to give me a list of facts and list of keywords from a whole document. Output should be like:\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124m    1) <fact 1>\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124m    My document to split: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcontent\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124m\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m---> 12\u001b[0m res \u001b[38;5;241m=\u001b[39m [x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplitting_prompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "Cell \u001b[0;32mIn[6], line 13\u001b[0m, in \u001b[0;36mgenerate\u001b[0;34m(prompt, system_prompt, max_new_tokens)\u001b[0m\n\u001b[1;32m      6\u001b[0m text \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mapply_chat_template(\n\u001b[1;32m      7\u001b[0m     messages,\n\u001b[1;32m      8\u001b[0m     tokenize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m      9\u001b[0m     add_generation_prompt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     10\u001b[0m )\n\u001b[1;32m     11\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m tokenizer([text], return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 13\u001b[0m generated_ids \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.00000001\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m generated_ids \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     19\u001b[0m     output_ids[\u001b[38;5;28mlen\u001b[39m(input_ids):] \u001b[38;5;28;01mfor\u001b[39;00m input_ids, output_ids \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(model_inputs\u001b[38;5;241m.\u001b[39minput_ids, generated_ids)\n\u001b[1;32m     20\u001b[0m ]\n\u001b[1;32m     22\u001b[0m response \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mbatch_decode(generated_ids, skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/generation/utils.py:2215\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2207\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2208\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2209\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   2210\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2211\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2212\u001b[0m     )\n\u001b[1;32m   2214\u001b[0m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[0;32m-> 2215\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2216\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2217\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2218\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2219\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2220\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2221\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2222\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2223\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2225\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[1;32m   2226\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[1;32m   2227\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[1;32m   2228\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   2229\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2234\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[1;32m   2235\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/generation/utils.py:3206\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   3203\u001b[0m model_inputs\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_hidden_states\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_hidden_states} \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;28;01melse\u001b[39;00m {})\n\u001b[1;32m   3205\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 3206\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   3208\u001b[0m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n\u001b[1;32m   3209\u001b[0m model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_model_kwargs_for_generation(\n\u001b[1;32m   3210\u001b[0m     outputs,\n\u001b[1;32m   3211\u001b[0m     model_kwargs,\n\u001b[1;32m   3212\u001b[0m     is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   3213\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py:1164\u001b[0m, in \u001b[0;36mQwen2ForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, num_logits_to_keep, **loss_kwargs)\u001b[0m\n\u001b[1;32m   1161\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1163\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1164\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1165\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1166\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1167\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1168\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1169\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1170\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1171\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1172\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1173\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1175\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1177\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1178\u001b[0m \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py:871\u001b[0m, in \u001b[0;36mQwen2Model.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    868\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m inputs_embeds\n\u001b[1;32m    870\u001b[0m \u001b[38;5;66;03m# create position embeddings to be shared across the decoder layers\u001b[39;00m\n\u001b[0;32m--> 871\u001b[0m position_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrotary_emb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    873\u001b[0m \u001b[38;5;66;03m# decoder layers\u001b[39;00m\n\u001b[1;32m    874\u001b[0m all_hidden_states \u001b[38;5;241m=\u001b[39m () \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py:157\u001b[0m, in \u001b[0;36mQwen2RotaryEmbedding.forward\u001b[0;34m(self, x, position_ids)\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dynamic_frequency_update(position_ids, device\u001b[38;5;241m=\u001b[39mx\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    156\u001b[0m \u001b[38;5;66;03m# Core RoPE block\u001b[39;00m\n\u001b[0;32m--> 157\u001b[0m inv_freq_expanded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minv_freq\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand\u001b[49m\u001b[43m(\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    158\u001b[0m position_ids_expanded \u001b[38;5;241m=\u001b[39m position_ids[:, \u001b[38;5;28;01mNone\u001b[39;00m, :]\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m    159\u001b[0m \u001b[38;5;66;03m# Force float32 (see https://github.com/huggingface/transformers/pull/29285)\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/_device.py:102\u001b[0m, in \u001b[0;36mDeviceContext.__torch_function__\u001b[0;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(cur_stack):\n\u001b[1;32m    100\u001b[0m         _push_mode(mode)\n\u001b[0;32m--> 102\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__torch_function__\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, types, args\u001b[38;5;241m=\u001b[39m(), kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    103\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m kwargs \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m _device_constructors() \u001b[38;5;129;01mand\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# res = find_disrepancies(hmi_file, ssts_file, calc_facts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impl_data = get_facts(hmi_file)\n",
    "# rules_data = get_facts(ssts_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(impl_data[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rules_data[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode and print the response\n",
    "response = generate(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m62.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tzdata>=2022.7\n",
      "  Downloading tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.6/346.6 KB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/nick/.local/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /home/nick/.local/lib/python3.10/site-packages (from pandas) (2.1.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Installing collected packages: tzdata, pandas\n",
      "Successfully installed pandas-2.2.3 tzdata-2024.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for doc_id 114671: 1.6420 seconds\n",
      "Time taken for doc_id 259571: 1.3202 seconds\n",
      "Time taken for doc_id 259572: 1.3211 seconds\n",
      "Time taken for doc_id 261611: 1.3199 seconds\n",
      "Time taken for doc_id 29448: 1.3198 seconds\n",
      "Time taken for doc_id 30364: 1.3230 seconds\n",
      "Time taken for doc_id 30365: 1.3216 seconds\n",
      "Time taken for doc_id 30370: 1.3244 seconds\n",
      "Time taken for doc_id 315231: 1.3237 seconds\n",
      "Time taken for doc_id 65831: 1.3297 seconds\n",
      "Time taken for doc_id 65832: 1.3286 seconds\n",
      "Time taken for doc_id 65833: 1.3291 seconds\n",
      "Time taken for doc_id 86921: 1.3279 seconds\n",
      "Time taken for doc_id 88001: 1.3252 seconds\n",
      "Time taken for doc_id 88002: 1.3270 seconds\n",
      "Average time taken per document: 1.3455 seconds\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "import pandas as pd\n",
    "hmi_prefix = \"/home/dev/case_data/test Атом/test data/HMI/UC-\"\n",
    "ssts_prefix = \"/home/dev/case_data/test Атом/test data/SSTS/SSTS-\"\n",
    "\n",
    "doc_ids = [114671, 259571, 259572, 261611, 29448, 30364, 30365, 30370, 315231, 65831, 65832, 65833, 86921, 88001, 88002 ]\n",
    "\n",
    "answer = {114671: \"NC\", 259571: \"LC\", 259572: \"FC\", 261611: \"LC\", 29448: \"LC\", 30364: \"LC\", 30365: \"LC\", 30370: \"LC\", 315231: \"LC\", 65831: \"FC\", 65832: \"LC\", 65833: \"LC\", 86921: \"NC\", 88001: \"LC\", 88002: \"LC\"}\n",
    "df = pd.DataFrame(columns=['Number', 'Name', 'Differences', 'Description', 'Compliance Level'])\n",
    "total_time = 0\n",
    "\n",
    "for doc_id in doc_ids:\n",
    "    \n",
    "    hmi_file = f\"{hmi_prefix}{doc_id}.docx\"\n",
    "    ssts_file = f\"{ssts_prefix}{doc_id}.docx\"\n",
    "    rules_data = process_file_hmi(ssts_file)\n",
    "    impl_data = process_docx_file_SSTS(hmi_file)\n",
    "    prompt = f\"\"\"\n",
    "    Evaluate the compliance of the document with the requirements using the rating system below:\n",
    "\n",
    "    **Compliance Categories:**\n",
    "    - FC (Fully Compliant): Perfect! Nothing can be improved.\n",
    "    - LC (Largely Compliant): Generally correct. Some improvements may be needed (described in comments). No need for review.\n",
    "    - PC (Partially Compliant): Major deviations. Improvements needed (described in comments). After improvement, review is required.\n",
    "    - NC (Non-Compliant): Not compliant. Needs to be re-done and re-reviewed. Directions for update shown in comments.\n",
    "    - NA (Not Applicable): Not applicable. Reason for non-applicability is described in comments.\n",
    "\n",
    "    ### Instructions:\n",
    "    1. Review the document content in \"File\" and compare it to the \"REQUIREMENTS\" provided.\n",
    "    2. Based on this comparison, assign the appropriate two-letter compliance code (e.g., FC, LC, PC, NC, or NA).\n",
    "\n",
    "    ### Notice (few-shot):\n",
    "\n",
    "    LC is returned if the notifications for battery status are slightly delayed, if the sound alerts for seatbelt reminders are missing, if the user interface occasionally lags for less than 1 second, if some minor glitches occur in the navigation system.\n",
    "\n",
    "    PC is returned if the regenerative braking system fails to engage properly at lower speeds, affecting braking consistency, if the navigation system misinterprets an address occasionally,\n",
    "\n",
    "    NC is returned if the emergency braking system fails to activate when necessary, posing a direct safety risk, if the battery management system reports inaccurate charge levels, function can only be used when the vehicle is in a stopped state.\n",
    "\n",
    "    NA is returned if the test involves an audio system, if IVI_IFT sends a video stream to SWP to notify the user\n",
    "\n",
    "    ### Data:\n",
    "    File: {impl_data[:50]}\n",
    "    REQUIREMENTS: {rules_data[:50]}\n",
    "\n",
    "    **Output Format**: Return ONLY ONE two-letter compliance code (e.g., FC, LC, PC, NC, or NA) as the final compliance rating. START YOUR ANSWER WITH THE CODE:\n",
    "    \"\"\"\n",
    "    \n",
    "    # Measure the time taken to generate the response\n",
    "    start_time = timeit.default_timer()\n",
    "    response = generate(prompt)\n",
    "    elapsed_time = timeit.default_timer() - start_time\n",
    "    total_time += elapsed_time\n",
    "    print(f\"Time taken for doc_id {doc_id}: {elapsed_time:.4f} seconds\")\n",
    "\n",
    "    # answer.append(response)\n",
    "    # response = \"NC\"\n",
    "\n",
    "    prompt2 = f\"\"\"\n",
    "Output the differences in factual data in these files knowing their compliance level:\n",
    "\n",
    "**Compliance Categories:**\n",
    "- FC (Fully Compliant): Perfect! Nothing can be improved.\n",
    "- LC (Largely Compliant): Generally correct. Some improvements may be needed (described in comments). No need for review.\n",
    "- PC (Partially Compliant): Major deviations. Improvements needed (described in comments). After improvement, review is required.\n",
    "- NC (Non-Compliant): Not compliant. Needs to be re-done and re-reviewed. Directions for update shown in comments.\n",
    "- NA (Not Applicable): Not applicable. Reason for non-applicability is described in comments.\n",
    "\n",
    "### Instructions:\n",
    "1. Review the document content in \"File\" and compare it to the \"REQUIREMENTS\" provided.\n",
    "2. Based on this comparison, assign the appropriate two-letter compliance code (e.g., FC, LC, PC, NC, or NA).\n",
    "\n",
    "### Data:\n",
    "Compliance level: {answer[doc_id]}\n",
    "File1 (use-case): {impl_data[:150]}\n",
    "File2 (requirements): {rules_data[:150]}\n",
    "\n",
    "**Output Format**:Json with fields \n",
    "    'one_line_of_text_from_file_one_with_mismatch': ...,\n",
    "    'one_line_of_text_from_file_two_with_mismatch': ...,\n",
    "    'summary_of_mismatch': ...,\n",
    "\"\"\"\n",
    "    \n",
    "    text = generate(prompt2, max_new_tokens=300)\n",
    "    start_index_1 = text.find('\"one_line_of_text_from_file_one_with_mismatch\":') + len('\"one_line_of_text_from_file_one_with_mismatch\": ')\n",
    "    end_index_1 = text.find('\",', start_index_1)\n",
    "    line1 = text[start_index_1+1:end_index_1]\n",
    "\n",
    "    start_index_2 = text.find('\"one_line_of_text_from_file_two_with_mismatch\":') + len('\"one_line_of_text_from_file_two_with_mismatch\": ')\n",
    "    end_index_2 = text.find('\",', start_index_2)\n",
    "    line2 = text[start_index_2+1:end_index_2]\n",
    "\n",
    "    start_index_3 = text.find('\"summary_of_mismatch\":') + len('\"summary_of_mismatch\": ')\n",
    "    end_index_3 = text.find('\"\\n', start_index_3)\n",
    "    line3 = text[start_index_3+1:end_index_3]\n",
    "\n",
    "    content = docx2python(ssts_file).text.split('\\n', 1)[0]\n",
    "    \n",
    "    \n",
    "    df = pd.concat([df, pd.DataFrame([{'Number': doc_id, 'Name': content, 'Differences': line3, 'Description': line1 + \"\\n\" + line2, 'Compliance Level': response}])], ignore_index=True)\n",
    "\n",
    "\n",
    "average_time = total_time / (len(doc_ids) + 0.000000001)\n",
    "print(f\"Average time taken per document: {average_time:.4f} seconds\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number</th>\n",
       "      <th>Name</th>\n",
       "      <th>Differences</th>\n",
       "      <th>Description</th>\n",
       "      <th>Compliance Level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>114671</td>\n",
       "      <td>Users can remotely control the DK deletion thr...</td>\n",
       "      <td>File1 does not contain any text related to rem...</td>\n",
       "      <td>\\nUsers can remotely control the DK deletion t...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>259571</td>\n",
       "      <td>Mute or pause function</td>\n",
       "      <td>File1 is empty while File2 contains structured...</td>\n",
       "      <td>\\nDocName: Mute or pause function, SectionName...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>259572</td>\n",
       "      <td>Mute or pause function</td>\n",
       "      <td>File1 is empty while File2 contains detailed r...</td>\n",
       "      <td>\\nText: , DocName: Mute or pause function, Sec...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>261611</td>\n",
       "      <td>Automatic search</td>\n",
       "      <td>File1 is empty while File2 contains structured...</td>\n",
       "      <td>\\nText: , DocName: Automatic search, SectionNa...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29448</td>\n",
       "      <td>Functional Description</td>\n",
       "      <td>File1 is empty, while File2 contains sections ...</td>\n",
       "      <td>\\nDocName: Functional Description, SectionName...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30364</td>\n",
       "      <td>Maximum charging SOC value setting</td>\n",
       "      <td>rmation, we need to identify any mismatches be...</td>\n",
       "      <td>ify any mismatches between `File1` and `File2`...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>30365</td>\n",
       "      <td>Functional Description</td>\n",
       "      <td>File1 is empty, hence no direct line-by-line m...</td>\n",
       "      <td>\\n</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>30370</td>\n",
       "      <td>Functional Description</td>\n",
       "      <td>File1 is empty, hence no direct line-by-line m...</td>\n",
       "      <td>\\n</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>315231</td>\n",
       "      <td>Favorite Song operation</td>\n",
       "      <td>File1 is empty while File2 contains structured...</td>\n",
       "      <td>\\nDocName: Favorite Song operation, SectionNam...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>65831</td>\n",
       "      <td>Make a call (B sample)</td>\n",
       "      <td>and instructions, let's analyze the differenc...</td>\n",
       "      <td>\\n[{ \\\"Text\\\": \\\"\\</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>65832</td>\n",
       "      <td>Make a call (B sample)</td>\n",
       "      <td>File1 is empty while File2 contains structured...</td>\n",
       "      <td>\\nText: , DocName: Make a call (B sample), Sec...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>65833</td>\n",
       "      <td>Make a call (B sample)</td>\n",
       "      <td>File1 is empty, while File2 contains structure...</td>\n",
       "      <td>\\nText: , DocName: Make a call (B sample), Sec...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>86921</td>\n",
       "      <td>Manual dialing E-CALL</td>\n",
       "      <td>File1 is empty while File2 contains detailed s...</td>\n",
       "      <td>\\nText: , DocName: Manual dialing E-CALL, Sect...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>88001</td>\n",
       "      <td>Receiving Call Notifications</td>\n",
       "      <td>File1 is empty while File2 contains structured...</td>\n",
       "      <td>\\nText: , DocName: Receiving Call Notification...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>88002</td>\n",
       "      <td>Receiving Call Notifications</td>\n",
       "      <td>File1 is empty while File2 contains structured...</td>\n",
       "      <td>\\nText: , DocName: Receiving Call Notification...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Number                                               Name  \\\n",
       "0   114671  Users can remotely control the DK deletion thr...   \n",
       "1   259571                             Mute or pause function   \n",
       "2   259572                             Mute or pause function   \n",
       "3   261611                                   Automatic search   \n",
       "4    29448                             Functional Description   \n",
       "5    30364                 Maximum charging SOC value setting   \n",
       "6    30365                             Functional Description   \n",
       "7    30370                             Functional Description   \n",
       "8   315231                            Favorite Song operation   \n",
       "9    65831                             Make a call (B sample)   \n",
       "10   65832                             Make a call (B sample)   \n",
       "11   65833                             Make a call (B sample)   \n",
       "12   86921                              Manual dialing E-CALL   \n",
       "13   88001                       Receiving Call Notifications   \n",
       "14   88002                       Receiving Call Notifications   \n",
       "\n",
       "                                          Differences  \\\n",
       "0   File1 does not contain any text related to rem...   \n",
       "1   File1 is empty while File2 contains structured...   \n",
       "2   File1 is empty while File2 contains detailed r...   \n",
       "3   File1 is empty while File2 contains structured...   \n",
       "4   File1 is empty, while File2 contains sections ...   \n",
       "5   rmation, we need to identify any mismatches be...   \n",
       "6   File1 is empty, hence no direct line-by-line m...   \n",
       "7   File1 is empty, hence no direct line-by-line m...   \n",
       "8   File1 is empty while File2 contains structured...   \n",
       "9    and instructions, let's analyze the differenc...   \n",
       "10  File1 is empty while File2 contains structured...   \n",
       "11  File1 is empty, while File2 contains structure...   \n",
       "12  File1 is empty while File2 contains detailed s...   \n",
       "13  File1 is empty while File2 contains structured...   \n",
       "14  File1 is empty while File2 contains structured...   \n",
       "\n",
       "                                          Description Compliance Level  \n",
       "0   \\nUsers can remotely control the DK deletion t...               NA  \n",
       "1   \\nDocName: Mute or pause function, SectionName...               NA  \n",
       "2   \\nText: , DocName: Mute or pause function, Sec...               NA  \n",
       "3   \\nText: , DocName: Automatic search, SectionNa...               NA  \n",
       "4   \\nDocName: Functional Description, SectionName...               NA  \n",
       "5   ify any mismatches between `File1` and `File2`...               NA  \n",
       "6                                                  \\n               NA  \n",
       "7                                                  \\n               NA  \n",
       "8   \\nDocName: Favorite Song operation, SectionNam...               NA  \n",
       "9                                  \\n[{ \\\"Text\\\": \\\"\\               NA  \n",
       "10  \\nText: , DocName: Make a call (B sample), Sec...               NA  \n",
       "11  \\nText: , DocName: Make a call (B sample), Sec...               NA  \n",
       "12  \\nText: , DocName: Manual dialing E-CALL, Sect...               NA  \n",
       "13  \\nText: , DocName: Receiving Call Notification...               NA  \n",
       "14  \\nText: , DocName: Receiving Call Notification...               NA  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PC']\n"
     ]
    }
   ],
   "source": [
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
